{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 15\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import math as math\n",
    "import random\n",
    "import os\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPAM = \"spmsg\"\n",
    "LEGIT = \"legit\"\n",
    "\n",
    "class Email:\n",
    "    def __init__(self, filename, lines):\n",
    "        self.filename = filename\n",
    "        self.isSpam = SPAM in filename\n",
    "        \n",
    "        self.title = list(map(int, (lines[0].strip().split())[1:]))\n",
    "        self.body = []\n",
    "        for line in lines[2:]:\n",
    "            self.body += list(map(int, line.strip().split()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        kind = \"LEGIT\"\n",
    "        if (self.isSpam):\n",
    "            kind = \"SPAM\"\n",
    "        return kind + \" EMAIL \" + self.filename + \": \" + str(self.title) + \", \" + str(self.body) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictValue:\n",
    "    def __init__(self):\n",
    "        self.sTitle = 0\n",
    "        self.lTitle = 0\n",
    "        self.sBody = 0\n",
    "        self.lBody = 0\n",
    "        \n",
    "    def foundInTitle(self, isSpam):\n",
    "        if (isSpam):\n",
    "            self.sTitle += 1\n",
    "        else:\n",
    "            self.lTitle += 1\n",
    "            \n",
    "    def foundInBody(self, isSpam):\n",
    "        if (isSpam):\n",
    "            self.sBody += 1\n",
    "        else:\n",
    "            self.lBody += 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        t = (self.sTitle, self.lTitle)\n",
    "        b = (self.sBody, self.lBody)\n",
    "        return \"TITLE: \" + str(t) + \", BODY: \" + str(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARTS_DIR = \"./Bayes/pu1/\"\n",
    "PARTS_NUM = 10\n",
    "\n",
    "def getData():\n",
    "    parts = []  \n",
    "    for i in range(PARTS_NUM):\n",
    "        curPart = PARTS_DIR + \"part\" + str(i + 1)\n",
    "        emails = []\n",
    "        for filename in os.listdir(curPart):\n",
    "            file = open(curPart + \"/\" + filename, 'r')\n",
    "            emails.append(Email(filename, file.readlines()))\n",
    "            file.close()\n",
    "        parts.append(emails)\n",
    "    return parts\n",
    "\n",
    "parts = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes: array of emails\n",
    "# returns: Dict where keys are words and values are DictValues (contain key-word statistic for all given emails)\n",
    "def learnBayes(emails):\n",
    "    dictName = {}\n",
    "    counters = [0, 0]\n",
    "    unique = set()\n",
    "    for email in emails:\n",
    "        for word in email.title:\n",
    "            unique.add(word)\n",
    "            dictName.setdefault(word, DictValue()).foundInTitle(email.isSpam)\n",
    "            if email.isSpam:\n",
    "                counters[0] += 1\n",
    "            else:\n",
    "                counters[1] += 1\n",
    "        for word in email.body:\n",
    "            unique.add(word)\n",
    "            dictName.setdefault(word, DictValue()).foundInBody(email.isSpam)\n",
    "            if email.isSpam:\n",
    "                counters[0] += 1\n",
    "            else:\n",
    "                counters[1] += 1\n",
    "\n",
    "    return dictName, counters, len(unique)\n",
    "            \n",
    "#print(learnBayes(parts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testBayes(spamDict, counters, emails, ns, n, q, z):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    min_diff = 10000000000\n",
    "    max_diff = -10000000000\n",
    "    for email in emails:\n",
    "        p_spam = math.log(ns / n)\n",
    "        p_legit = math.log((n - ns) / n)\n",
    "        \n",
    "        for word in email.title:\n",
    "            wf = spamDict.get(word, DictValue())\n",
    "            p_spam += math.log((wf.sTitle + wf.sBody + z) / (counters[0] + z * q))\n",
    "            p_legit += math.log((wf.lTitle + wf.lBody + z) / (counters[1] + z * q))\n",
    "\n",
    "        for word in email.body:\n",
    "            wf = spamDict.get(word, DictValue())\n",
    "            p_spam += math.log((wf.sTitle + wf.sBody + z) / (counters[0] + q * z))\n",
    "            p_legit += math.log((wf.lTitle + wf.lBody + z) / (counters[1] + q * z))\n",
    "\n",
    "        isCurrentSpam = p_spam > p_legit\n",
    "        if (email.isSpam != isCurrentSpam):\n",
    "            if isCurrentSpam:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if isCurrentSpam:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        \n",
    "        if (p_spam - p_legit > max_diff):\n",
    "            max_diff = p_spam - p_legit\n",
    "        if (p_spam - p_legit < min_diff):\n",
    "            min_diff = p_spam - p_legit\n",
    "    if TP == 0:\n",
    "        return 0\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    print(FP)\n",
    "\n",
    "    return 2 * (precision * recall) / (precision + recall), min_diff, max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cv():\n",
    "    best_result = None\n",
    "    best_score  = -1\n",
    "\n",
    "    min_best = 10000000000\n",
    "    max_best = -10000000000\n",
    "    aver = 0\n",
    "    for i in range(PARTS_NUM):\n",
    "        learningSet = []\n",
    "        for j in range(PARTS_NUM):\n",
    "            if (j != i):\n",
    "                learningSet += parts[j]\n",
    "                \n",
    "        ns = 0\n",
    "        n = len(learningSet)\n",
    "        for email in learningSet:\n",
    "            if (email.isSpam):\n",
    "                ns += 1\n",
    "                \n",
    "        testingSet  = parts[i]\n",
    "        \n",
    "        \n",
    "        spamDict, counters, unique = learnBayes(learningSet)\n",
    "        score, min_diff, max_diff = testBayes(spamDict, counters, testingSet, ns, n, unique, 0.01706422018348624)\n",
    "\n",
    "        if score > best_score:\n",
    "            min_best = min_diff\n",
    "            max_best = max_diff\n",
    "            best_score = score\n",
    "            best_result = spamDict, counters, testingSet, ns, n, unique\n",
    "        print(score)\n",
    "        aver += score\n",
    "    print(\"Average:\", aver / PARTS_NUM)\n",
    "    \n",
    "    return best_result, min_best, max_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, min_v, max_v = cv()\n",
    "spamDict, counters, testingSet, ns, n, unique = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getF1Score(res, diff):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for (d, p_spam, p_legit, isSpam) in res:\n",
    "        isCurrentSpam = d > diff\n",
    "        if (isSpam != isCurrentSpam):\n",
    "            if isCurrentSpam:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if isCurrentSpam:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "                \n",
    "    if TP == 0:\n",
    "        return 0\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    #print(\"FP\", FP)\n",
    "\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "\n",
    "def testBayes2(spamDict, counters, emails, ns, n, q, z):\n",
    "    res = []\n",
    "    for email in emails:\n",
    "        p_spam = math.log(ns / n)\n",
    "        p_legit = math.log((n - ns) / n)\n",
    "        \n",
    "        for word in email.title:\n",
    "            wf = spamDict.get(word, DictValue())\n",
    "            p_spam += math.log((wf.sTitle + wf.sBody + z) / (counters[0] + z * q))\n",
    "            p_legit += math.log((wf.lTitle + wf.lBody + z) / (counters[1] + z * q))\n",
    "\n",
    "        for word in email.body:\n",
    "            wf = spamDict.get(word, DictValue())\n",
    "            p_spam += math.log((wf.sTitle + wf.sBody + z) / (counters[0] + q * z))\n",
    "            p_legit += math.log((wf.lTitle + wf.lBody + z) / (counters[1] + q * z))\n",
    "    \n",
    "        res.append((p_spam - p_legit, p_spam, p_legit, email.isSpam))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv2():\n",
    "    best_result = None\n",
    "    best_score  = -1\n",
    "\n",
    "    for i in range(PARTS_NUM):\n",
    "        learningSet = []\n",
    "        for j in range(PARTS_NUM):\n",
    "            if (j != i):\n",
    "                learningSet += parts[j]\n",
    "                \n",
    "        ns = 0\n",
    "        n = len(learningSet)\n",
    "        for email in learningSet:\n",
    "            if (email.isSpam):\n",
    "                ns += 1\n",
    "                \n",
    "        testingSet  = parts[i]\n",
    "        \n",
    "        \n",
    "        spamDict, counters, unique = learnBayes(learningSet)\n",
    "        res = testBayes2(spamDict, counters, testingSet, ns, n, unique, 0.01706422018348624)\n",
    "        score = getF1Score(res, 0)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_result = spamDict, counters, testingSet, ns, n, unique\n",
    "        print(score)\n",
    "    \n",
    "    return best_result\n",
    "\n",
    "\n",
    "def getDiffs():\n",
    "    diffs = []\n",
    "    for i in range(PARTS_NUM):\n",
    "        learningSet = []\n",
    "        for j in range(PARTS_NUM):\n",
    "            if (j != i):\n",
    "                learningSet += parts[j]\n",
    "                \n",
    "        ns = 0\n",
    "        n = len(learningSet)\n",
    "        for email in learningSet:\n",
    "            if (email.isSpam):\n",
    "                ns += 1\n",
    "                \n",
    "        testingSet  = parts[i]\n",
    "        \n",
    "        \n",
    "        spamDict, counters, unique = learnBayes(learningSet)\n",
    "        res = testBayes2(spamDict, counters, testingSet, ns, n, unique, 0.01706422018348624)\n",
    "        diffs += res\n",
    "    \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = getDiffs()\n",
    "\n",
    "print(getF1Score(diffs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l = min(diffs)[0] - 1\n",
    "d_r = max(diffs)[0] + 1\n",
    "\n",
    "diffsT = [x[0] for x in diffs if x[3]]         #spam\n",
    "diffsF = [x[0] for x in diffs if not x[3]]     # ham\n",
    "\n",
    "diffsT.sort(reverse=True)\n",
    "diffsF.sort(reverse=True)\n",
    "\n",
    "print(d_l)\n",
    "print(d_r)\n",
    "#print(diffsT)\n",
    "\n",
    "npoints = []\n",
    "\n",
    "x = d_r\n",
    "curT = 0\n",
    "curF = 0\n",
    "while (x >= d_l):   # x = spam - ham  from max to min\n",
    "    x -= 1\n",
    "    \n",
    "    #TP for spam\n",
    "    while ((curT < len(diffsT)) and (diffsT[curT] > x)):\n",
    "        curT += 1\n",
    "    \n",
    "    #FP for spam\n",
    "    while ((curF < len(diffsF)) and (diffsF[curF] > x)):\n",
    "        curF += 1\n",
    "    \n",
    "    npoints.append((curT/len(diffsT), curF/len(diffsF)))\n",
    "\n",
    " \n",
    "points = []\n",
    "\n",
    "for TPR, FPR in npoints:\n",
    "    points += [np.array([TPR, FPR])]\n",
    "\n",
    "points = np.array(points)\n",
    "\n",
    "print(points)\n",
    "plt.plot(points[:,1], points[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffs2 = getDiffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l = min(diffs2)[0] - 1\n",
    "d_r = max(diffs2)[0] + 1\n",
    "\n",
    "diffsT = [x[0] for x in diffs2 if x[3]]         #spam\n",
    "diffsF = [x[0] for x in diffs2 if not x[3]]     # ham\n",
    "\n",
    "diffsT.sort(reverse=True)\n",
    "diffsF.sort(reverse=True)\n",
    "\n",
    "p_min = diffsT[-1]\n",
    "n_max = diffsF[0]\n",
    "\n",
    "tresh = None\n",
    "if (p_min < n_max):\n",
    "    print(p_min)\n",
    "    tresh = p_min\n",
    "else:\n",
    "    print(n_max)\n",
    "    tresh = n_max\n",
    "    \n",
    "print(getF1Score(diffs2, tresh))\n",
    "\n",
    "print(\"diffs\", d_l, d_r)\n",
    "#print(diffsT)\n",
    "\n",
    "npoints = []\n",
    "\n",
    "x = d_r\n",
    "curT = 0\n",
    "curF = 0\n",
    "\n",
    "fsc = 0\n",
    "t = 0\n",
    "\n",
    "while (x >= d_l):   # x = spam - ham  from max to min\n",
    "    x -= 1\n",
    "    \n",
    "    #TP for spam\n",
    "    while ((curT < len(diffsT)) and (diffsT[curT] > x)):\n",
    "        curT += 1\n",
    "    \n",
    "    #FP for spam\n",
    "    while ((curF < len(diffsF)) and (diffsF[curF] > x)):\n",
    "        curF += 1\n",
    "    \n",
    "    \n",
    "    # isCurrentSpam = d > diff\n",
    "    #письма из спама, которые детектятся, как спам\n",
    "    #письма из ок, которые детектятся, как спам\n",
    "    #хотим занулить curF - ок письма, которые детектятся, как спам \n",
    "    f = getF1Score(diffs2, x)\n",
    "    if ((curF < 3) and (f > fsc)):\n",
    "        t = x\n",
    "        fsc = f\n",
    "    \n",
    "    npoints.append((curT/len(diffsT), curF/len(diffsF)))\n",
    "\n",
    "\n",
    "print(\"trash hold:\", t, \", fscore:\",  fsc)\n",
    "#print(\"trash hold:\", t, \", fscore:\",  getF1Score(diffs2, 0))\n",
    "\n",
    "points = []\n",
    "\n",
    "for TPR, FPR in npoints:\n",
    "    points += [np.array([TPR, FPR])]\n",
    "\n",
    "points = np.array(points)\n",
    "\n",
    "print(points)\n",
    "plt.plot(points[:,1], points[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
