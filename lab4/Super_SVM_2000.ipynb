{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 15\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats as sps\n",
    "import scipy.optimize as sopt\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"chips.txt\", sep=',', header = None)\n",
    "\n",
    "xy = data.values[:, :2]\n",
    "color = data.values[:, 2].astype('int')\n",
    "\n",
    "for i in range(len(color)):\n",
    "    if (color[i] == 0):\n",
    "        color[i] = -1\n",
    "        \n",
    "perm = list(range(len(xy)))\n",
    "random.shuffle(perm)\n",
    "xy = xy[perm]\n",
    "color = color[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_number = 0\n",
    "\n",
    "def printAllPoints(xy, color):\n",
    "    global plot_number\n",
    "    green = [[], []]\n",
    "    blue = [[], []]\n",
    "    for i in range(len(xy)):\n",
    "        if (color[i] != 1):\n",
    "            green[0].append(xy[i, 0])\n",
    "            green[1].append(xy[i, 1])\n",
    "        else:\n",
    "            blue[0].append(xy[i, 0])\n",
    "            blue[1].append(xy[i, 1])\n",
    "    plot_number += 1\n",
    "    plt.title(str(plot_number))\n",
    "    plt.plot(green[0], green[1], 'g.', blue[0], blue[1], 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawPrediction(plot_name, xy, actual, classifier):\n",
    "    classifier.fit(xy, actual)\n",
    "    \n",
    "    xs = [p[0] for p in xy]\n",
    "    ys = [p[1] for p in xy]\n",
    "    green = [[], []]\n",
    "    blue = [[], []]\n",
    "    \n",
    "    eps = 0.1\n",
    "           \n",
    "    for x in np.arange(min(xs) - eps, max(xs) + eps, 0.01):\n",
    "        for y in np.arange(min(ys) - eps, max(ys) + eps, 0.01):\n",
    "            predicted = classifier.predict(np.array([[x, y]]))\n",
    "\n",
    "            if (predicted != 1):\n",
    "                green[0].append(x)\n",
    "                green[1].append(y)\n",
    "            else:\n",
    "                blue[0].append(x)\n",
    "                blue[1].append(y)\n",
    "\n",
    "    plt.title(plot_name)\n",
    "    plt.plot(green[0], green[1], 'xkcd:lightgreen', blue[0], blue[1], '#ADD8E6')\n",
    "    \n",
    "    printAllPoints(xy, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAllPoints(xy, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConfusion(predicted, actual):\n",
    "    true_positive  = np.sum(np.logical_and(predicted == 1, predicted == actual))\n",
    "    false_positive = np.sum(np.logical_and(predicted == 1, predicted != actual))\n",
    "    false_negative  = np.sum(np.logical_and(predicted != 1, predicted != actual))\n",
    "    true_negative = np.sum(np.logical_and(predicted != 1, predicted == actual))\n",
    "\n",
    "    return [[true_positive, false_positive], [false_negative, true_negative]]\n",
    "    \n",
    "\n",
    "def getF1Score(conf):\n",
    "    tp, fp = conf[0]\n",
    "    fn, tn = conf[1]\n",
    "    \n",
    "    recall = 0\n",
    "    if (tp + fn != 0):\n",
    "        recall = (1.0 * tp) / (tp + fn)\n",
    "    \n",
    "    precision = 0\n",
    "    if (tp + fp != 0):\n",
    "        precision = (1.0 * tp) / (tp + fp)\n",
    "    \n",
    "    f1 = 0\n",
    "    if (precision + recall > 0):\n",
    "        f1 = 2.0 * precision * recall / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(classifier, k = 10):    \n",
    "    xy_parts = np.array_split(xy, k)\n",
    "    color_parts = np.array_split(color, k)\n",
    "    \n",
    "    result = np.array([])\n",
    "    for i in range(k):\n",
    "        xy_train = np.concatenate(np.delete(xy_parts, i, 0))\n",
    "        color_train = np.concatenate(np.delete(color_parts, i, 0))\n",
    "        xy_test = xy_parts[i]\n",
    "        \n",
    "        classifier.fit(xy_train, color_train)\n",
    "        result = np.append(result, classifier.predict(xy_test))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_kernel(x, y):\n",
    "    return np.dot(x, y) ** 2\n",
    "\n",
    "def paraboloid_kernel(x, y):\n",
    "    return np.dot([x[0], x[1], x[0]**2 + x[1]**2], [y[0], y[1], y[0]**2 + y[1]**2])\n",
    "\n",
    "def getCenter():\n",
    "    x0, y0 = 0, 0\n",
    "    for p in xy:\n",
    "        x0 += p[0]\n",
    "        y0 += p[1]\n",
    "    x0 = x0 / len(xy)\n",
    "    y0 = y0 / len(xy)\n",
    "    return np.array([x0, y0])\n",
    "\n",
    "center = getCenter()\n",
    "\n",
    "def parab(x, y):\n",
    "    return square_kernel(\n",
    "        [x[0], x[1], (x[0] - center[0])**2 + (x[1] - center[1])**2], \n",
    "        [y[0], y[1], (y[0] - center[0])**2 + (y[1] - center[1])**2]\n",
    "    )\n",
    "\n",
    "\n",
    "def paraboloid_kernel2(x, y):\n",
    "    return square_kernel([x[0], x[1], x[0]**2 + x[1]**2], [y[0], y[1], y[0]**2 + y[1]**2])\n",
    "\n",
    "def gaussianKernel(sigma=1):\n",
    "    FG = lambda x : np.array([(x[0]**2 + x[1]**2) , x[0], x[1]])\n",
    "    return lambda x, y: np.exp(-np.dot(FG(np.array(x) - np.array(y)),  FG(np.array(x) - np.array(y))) / (2 * (sigma ** 2)))\n",
    "                  \n",
    "def poly_kernel(x, y):\n",
    "    return (sum(np.array(x) * np.array(y)) * 0.1 + 1)**4\n",
    "\n",
    "\n",
    "def expKern(x, y):\n",
    "    return 2.7182818284590452354 ** (- (np.linalg.norm(np.array(x) - np.array(y)) ** 2) / 2)\n",
    "\n",
    "def poly3(x, y):\n",
    "    return (np.dot(np.array(x), np.array(y)) + 1) ** 3\n",
    "\n",
    "def wikiKern(x, y):\n",
    "    npx, npy = np.array(x), np.array(y)\n",
    "    return np.dot(npx, npy)  + (np.linalg.norm(npx) ** 2) * (np.linalg.norm(npy) ** 2)\n",
    "\n",
    "svm_kernels = [(np.dot, '<x, y>'),\n",
    "               (expKern, 'expKern'),\n",
    "               (poly3, 'poly3'),\n",
    "               (poly_kernel, 'polynomial'),\n",
    "               (paraboloid_kernel, 'paraboloid_kernel'),\n",
    "               (square_kernel, 'square_kerne'),\n",
    "               (paraboloid_kernel2, 'paraboloid_kernel2'),\n",
    "               (parab, 'square paraboloid')\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SuperSvm():\n",
    "    \n",
    "    def __init__(self, c, kernel):\n",
    "        self.c = c\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, xy, color):\n",
    "        n = len(xy)\n",
    "        vect_c = self.c * np.ones(n)\n",
    "        lagrange_gradient = np.fromfunction(\n",
    "            np.vectorize(lambda i, j: color[i] * color[j] * self.kernel(xy[i], xy[j])),\n",
    "            (n, n), \n",
    "            dtype=int\n",
    "        )\n",
    "        \n",
    "        start = np.random.randn(n)\n",
    "        cons = [ {\"type\": \"eq\",   \"fun\": lambda x: np.dot(color, x)}# , \"jac\": lambda x: color}\n",
    "               , {\"type\": \"ineq\", \"fun\": lambda x: x} #,                \"jac\": lambda x:  np.eye(n)}\n",
    "               , {\"type\": \"ineq\", \"fun\": lambda x: vect_c - x}] #,       \"jac\": lambda x: -np.eye(n)}]\n",
    "        \n",
    "        lagrange = lambda x: 0.5 * np.dot(x.T, np.dot(lagrange_gradient, x)) - np.dot(vect_c, x)\n",
    "        lagrange_jac = lambda x: np.dot(x.T, lagrange_gradient) - vect_c\n",
    "        \n",
    "        #и здесь тоже\n",
    "        lambdas = sopt.minimize(lagrange, \n",
    "                                np.random.randn(n), \n",
    "                                #jac=lagrange_jac, \n",
    "                                constraints=cons)\n",
    "        \n",
    "        dim = len(xy[0])\n",
    "        self.w = np.array([0 for i in range(dim)], dtype='float64')\n",
    "        for i in range(len(xy)):\n",
    "            lambda_i = lambdas.x[i]\n",
    "            color_i = color[i]\n",
    "            point_i = xy[i]\n",
    "            self.w += np.array([lambda_i * color_i * point_i[j] for j in range(dim)], dtype='float64')\n",
    "            \n",
    "      \n",
    "        self.l_y = lambdas.x * color\n",
    "        self.xy = xy\n",
    "        \n",
    "        support_indices = np.nonzero(np.logical_and(lambdas.x > eps, lambdas.x < self.c - eps))[0]\n",
    "#         print(support_indices, opt.x[support_indices])\n",
    "        self.w_0 = 0\n",
    "        if (len(support_indices) > 0):\n",
    "            sv_index = support_indices[0]\n",
    "            self.w_0 = np.dot(self.l_y, self.kernel_vec(xy[sv_index])) - color[sv_index]    \n",
    "        \n",
    "        self.w0 = 0\n",
    "        count = 0\n",
    "        for i in range(len(lambdas.x)):\n",
    "            lambda_i = lambdas.x[i]\n",
    "            if lambda_i > 0:\n",
    "                self.w0 += self.kernel(self.w, xy[i]) - color[i]\n",
    "                count += 1\n",
    "        if count != 0:\n",
    "            self.w0 /= count\n",
    "                \n",
    "    \n",
    "    def kernel_vec(self, point):\n",
    "        return np.apply_along_axis(lambda xy: self.kernel(xy, point), 1, self.xy) \n",
    "\n",
    "    def predict(self, points):\n",
    "        ans = []\n",
    "        for point in points:\n",
    "            if (np.dot(self.l_y, self.kernel_vec(point)) - self.w_0) > 0:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(-1)\n",
    "        return np.array(ans, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['c', 'kernel', 'f1'])\n",
    "svm_best_result = 0\n",
    "svm_best_params = ()\n",
    "\n",
    "eps = 1e-8\n",
    "\n",
    "for c in [1, 1.2, 1.3, 1.5, 2]:\n",
    "    print(c)\n",
    "    for kernel in svm_kernels:\n",
    "        svm_classifier = SuperSvm(c, kernel[0])\n",
    "        predicted = k_fold_cv(svm_classifier)\n",
    "        conf = getConfusion(predicted, color)\n",
    "        cur_f1 = getF1Score(conf)\n",
    "          \n",
    "        raw = pd.DataFrame([[c, kernel[1], cur_f1]], columns=['c','kernel', 'f1'])\n",
    "        #print(raw)\n",
    "        results = results.append(raw, ignore_index=True)\n",
    "               \n",
    "        if (cur_f1 > svm_best_result):\n",
    "            svm_best_result = cur_f1\n",
    "            svm_best_params = (c, kernel)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None):\n",
    "#    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, kernel = svm_best_params\n",
    "print(svm_best_result, \"c:\", c, \"kernel:\", kernel[1])\n",
    "drawPrediction('svn_best', xy, color, SuperSvm(c, kernel[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowskiDistance(x, y, p):\n",
    "    res = 0\n",
    "    for i in range(len(x)):\n",
    "        res += abs(x[i] - y[i]) ** p\n",
    "    return res ** (1 / p)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "def cosineSimilarity(x, y):\n",
    "    res, a, b = 0, 0, 0\n",
    "    for i in range(len(x)):\n",
    "        res += x[i] * y[i]\n",
    "        a += x[i] ** 2\n",
    "        b += y[i] ** 2\n",
    "    a = a ** (1 / 2)\n",
    "    b = b ** (1 / 2)\n",
    "    return res / a / b\n",
    "\n",
    "knn_metrics = [\n",
    "    (lambda x, y: minkowskiDistance(x, y, 1), 'minkowski_1'), \n",
    "    (lambda x, y: minkowskiDistance(x, y, 2), 'minkowski_2')\n",
    "]   \n",
    "\n",
    "\n",
    "knn_kernels = [\n",
    "    (lambda x: 1 / 2, 'uniform'),\n",
    "    (lambda x: 1 - abs(x), 'triangular'),\n",
    "    (lambda x: 3 / 4 * (1 - x * x), 'parabolic'),\n",
    "    (lambda x: (1 - x ** 2) ** 2 * 15 / 16, 'quartic')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def toPolar(p1, p0):\n",
    "    x, y = p1[0] - p0[0], p1[1] - p0[1]\n",
    "    r = (x ** 2 + y ** 2) ** 0.5\n",
    "    a = math.atan2(x, y)\n",
    "    return np.array([r, a])\n",
    "\n",
    "def getCenter():\n",
    "    x0, y0 = 0, 0\n",
    "    for p in xy:\n",
    "        x0 += p[0]\n",
    "        y0 += p[1]\n",
    "    x0 = x0 / len(xy)\n",
    "    y0 = y0 / len(xy)\n",
    "    return np.array([x0, y0])\n",
    "\n",
    "center = getCenter()\n",
    "\n",
    "knn_transform = [\n",
    "    (lambda p: p, '-'),\n",
    "    (lambda p: np.array([p[0], p[0] + p[1]]), 'sum'),\n",
    "    (lambda p: toPolar(p, np.array([0, 0])), 'polar'),\n",
    "    (lambda p: toPolar(p, center), 'polar2'),\n",
    "    (\n",
    "        lambda p: np.array([toPolar(p, center)[0] * 10, toPolar(p, center)[0] + toPolar(p, center)[1]]),\n",
    "        'wide'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class knn():\n",
    "    def __init__(self, k, metric, kernel, transform):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.kernel = kernel\n",
    "        self.transform = transform\n",
    "        \n",
    "    def fit(self, xy, color):\n",
    "        res = []\n",
    "        for p in xy:\n",
    "            res.append(self.transform(p))\n",
    "        self.xy = np.array(res)\n",
    "        #printAllPoints(self.xy, color)\n",
    "        self.n = len(xy)\n",
    "        self.color = color\n",
    "        \n",
    "    def predictPoint(self, p):\n",
    "        point = self.transform(p)\n",
    "        dist = [(self.metric(self.xy[i], point), i) for i in range(self.n)]\n",
    "        dist.sort()\n",
    "        d = dist[self.k][0]\n",
    "        if (d == 0):\n",
    "            d = 1\n",
    "        s = [0] * 3\n",
    "        for i in range(k):\n",
    "            cur_dist, index = dist[i]\n",
    "            s[self.color[index] + 1] += self.kernel(cur_dist / d)\n",
    "        if (s[0] > s[2]):\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "               \n",
    "    def predict(self, points):\n",
    "        res = [self.predictPoint(point) for point in points]   \n",
    "        return np.array(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['transform', 'k', 'metric'])\n",
    "\n",
    "knn_best_result = 0\n",
    "knn_best_params = []\n",
    "\n",
    "for transform in knn_transform:\n",
    "    for k in [4, 5, 6, 7, 8]:\n",
    "        for metric in knn_metrics:\n",
    "            for kernel in knn_kernels:\n",
    "                knn_classifier = knn(k, metric[0], kernel[0], transform[0])\n",
    "                predicted = k_fold_cv(knn_classifier)\n",
    "                conf = getConfusion(predicted, color)\n",
    "                cur_f1 = getF1Score(conf)\n",
    "                \n",
    "                raw = pd.DataFrame([[transform[1], k, metric[1], kernel[1], cur_f1]], columns=['transform', 'k', 'metric', 'kernel', 'f1'])\n",
    "                results = results.append(raw, ignore_index=True)\n",
    "               \n",
    "                if (cur_f1 > knn_best_result):\n",
    "                    knn_best_result = cur_f1\n",
    "                    knn_best_params = (transform, k, metric, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None):\n",
    "#    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, k, metric, kernel = knn_best_params\n",
    "print(knn_best_result, \"transform:\", transform[1], \"k:\", k, metric[1], kernel[1])\n",
    "drawPrediction('knn_best_' + str(i), xy, color, knn(k, metric[0], kernel[0], transform[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# H0: difference between predicted classes follows a symmetric distribution around zero.\n",
    "# H1: difference between predicted does not follow a symmetric distribution around zero.\n",
    "\n",
    "# reference link: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
    "\n",
    "# two-sided, for one-sided count only + or - values\n",
    "# Significance Level: 0.01 or 0.05?\n",
    "def getWilcoxonRank(res1, res2):\n",
    "    diff = []\n",
    "    for i in range(len(res1)):\n",
    "        if (res2[i] - res1[i] != 0):\n",
    "            m = abs(res2[i] - res1[i])\n",
    "            diff.append([m, (res2[i] - res1[i]) / m, 0])\n",
    "    diff.sort()\n",
    "    n = len(diff)\n",
    "\n",
    "    for r in range(n):\n",
    "        diff[r][2] = r + 1\n",
    "    \n",
    "    i = 0\n",
    "    while (i < n):\n",
    "        s = 0\n",
    "        prev = i\n",
    "        while ((i < n) and (diff[i][0] == diff[prev][0])):\n",
    "            s += diff[i][2]\n",
    "            i += 1\n",
    "        if (i - prev > 1):\n",
    "            for t in range(prev, i):\n",
    "                diff[t][2] = s / (i - prev)\n",
    "    \n",
    "    ans_m = 0\n",
    "    ans_p = 0\n",
    "    for i in range(n):\n",
    "        if (diff[i][1] * diff[i][2] < 0):\n",
    "            ans_m -= diff[i][1] * diff[i][2]\n",
    "        else:\n",
    "            ans_p += diff[i][1] * diff[i][2]\n",
    "    \n",
    "    w = min(ans_p, ans_m)\n",
    "    mu  = (n * (n + 1) * 1.0) / 4.0\n",
    "    std = (n * (n + 1) * (2 * n + 1) / 24.0) ** 0.5\n",
    "    z   = (w - mu) / std\n",
    "    \n",
    "    pval = 2. * norm.sf(abs(z))\n",
    "    \n",
    "    return (w, z, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, svm_kernel = svm_best_params\n",
    "transform, k, metric, knn_kernel = knn_best_params\n",
    "\n",
    "knn_f1_arr = []\n",
    "svm_f1_arr = []\n",
    "\n",
    "svm_predicted = k_fold_cv(svm_classifier)\n",
    "svm_conf = getConfusion(svm_predicted, color)\n",
    "svm_f1 = getF1Score(svm_conf)\n",
    "\n",
    "knn_predicted = k_fold_cv(knn_classifier)\n",
    "knn_conf = getConfusion(knn_predicted, color)\n",
    "knn_f1 = getF1Score(knn_conf)\n",
    "\n",
    "parts_n = 10\n",
    "xy_parts = np.array_split(xy, parts_n)\n",
    "color_parts = np.array_split(color, parts_n)\n",
    "for i in range(parts_n):\n",
    "    xy_train = np.concatenate(np.delete(xy_parts, i, 0))\n",
    "    color_train = np.concatenate(np.delete(color_parts, i, 0))\n",
    "    xy_test = xy_parts[i]\n",
    "    color_test = color_parts[i]\n",
    "    \n",
    "    svm_classifier = SuperSvm(c, svm_kernel[0])\n",
    "    knn_classifier = knn(k, metric[0], knn_kernel[0], transform[0])\n",
    "    svm_classifier.fit(xy_train, color_train)\n",
    "    knn_classifier.fit(xy_train, color_train)\n",
    "    \n",
    "    knn_f1_arr.append(getF1Score(getConfusion(knn_classifier.predict(xy_test), color_test)))\n",
    "    svm_f1_arr.append(getF1Score(getConfusion(svm_classifier.predict(xy_test), color_test)))\n",
    "\n",
    "\n",
    "print(knn_f1_arr)\n",
    "print(svm_f1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wr2 = scipy.stats.wilcoxon(svm_f1_arr, knn_f1_arr)\n",
    "#print(\"WR2:\", wr2)\n",
    "\n",
    "# If p > .10 → “not significant”\n",
    "# If p ≤ .10 → “marginally significant”\n",
    "# If p ≤ .05 → “significant”\n",
    "# If p ≤ .01 → “highly significant.”\n",
    "w, z, pvalue = getWilcoxonRank(svm_f1_arr, knn_f1_arr)\n",
    "print(\"WR: w=\", w, \", z=\", z, \", pval=\", pvalue, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, svm_kernel = svm_best_params\n",
    "svm_classifier = SuperSvm(c, svm_kernel[0])\n",
    "svm_predicted = k_fold_cv(svm_classifier)\n",
    "svm_conf = getConfusion(svm_predicted, color)\n",
    "svm_f1 = getF1Score(svm_conf)\n",
    "\n",
    "transform, k, metric, knn_kernel = knn_best_params\n",
    "knn_classifier = knn(k, metric[0], knn_kernel[0], transform[0])\n",
    "knn_predicted = k_fold_cv(knn_classifier)\n",
    "knn_conf = getConfusion(knn_predicted, color)\n",
    "knn_f1 = getF1Score(knn_conf)\n",
    "\n",
    "print(\"svm f1:\", svm_f1)\n",
    "print(\"knn f1:\", knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
