{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 15\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import scipy.optimize as sopt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printAllPoints(data, classes):\n",
    "    green = [[], []]\n",
    "    blue = [[], []]\n",
    "    for (x, y) in data:\n",
    "        if (classes[(x, y)] == 0):\n",
    "            green[0].append(x)\n",
    "            green[1].append(y)\n",
    "        else:\n",
    "            blue[0].append(x)\n",
    "            blue[1].append(y)\n",
    "    plt.plot(green[0], green[1], 'g.', blue[0], blue[1], 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(transform, name):\n",
    "    fin = open('chips.txt', 'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "    \n",
    "    classes = dict()\n",
    "    data = list()\n",
    "    \n",
    "    for x, y, z in [map(float, x.split(',')) for x in lines]:\n",
    "        a, b = transform(x, y)\n",
    "        data.append((a, b))\n",
    "        classes[(a, b)] = z\n",
    "    \n",
    "    return (data, classes, name, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toPolar(x, y, x0, y0):\n",
    "    x, y = x - x0, y - y0\n",
    "    r = (x ** 2 + y ** 2) ** (1 / 2)\n",
    "    a = math.atan2(x, y)\n",
    "    return (r, a)\n",
    "\n",
    "def getCenter():\n",
    "    fin = open('chips.txt', 'r')\n",
    "    lines = fin.readlines()\n",
    "    fin.close()\n",
    "\n",
    "    x0, y0 = 0, 0\n",
    "    for x, y, z in [map(float, x.split(',')) for x in lines]:\n",
    "        x0 += x\n",
    "        y0 += y\n",
    "    x0 = x0 / len(lines)\n",
    "    y0 = y0 / len(lines)\n",
    "    \n",
    "    return (x0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleData = get_data(lambda x, y:(x, y), '-')\n",
    "sumData = get_data(lambda x, y:(x, x + y), 'x, y -> x, x + y')\n",
    "polarData = get_data(lambda x, y: toPolar(x, y, 0, 0), 'polar(0, 0)')\n",
    "\n",
    "center = getCenter()\n",
    "polarData2 = get_data(lambda x, y: toPolar(x, y, center[0], center[1]), 'polar(center_x, center_y)')\n",
    "\n",
    "wideData = get_data(lambda x, y: ( toPolar(x, y, center[0], center[1])[0] * 10 \n",
    "                                 , toPolar(x, y, center[0], center[1])[0] + toPolar(x, y, center[0], center[1])[1]\n",
    "                                 )\n",
    "                    , 'wide')\n",
    "\n",
    "\n",
    "data = [simpleData, sumData, polarData, polarData2, wideData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printAllPoints(wideData[0], wideData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printAllPoints(simpleData[0], simpleData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printAllPoints(sumData[0], sumData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printAllPoints(polarData[0], polarData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printAllPoints(polarData2[0], polarData2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowskiDistance(x, y, p):\n",
    "    res = 0\n",
    "    for i in range(len(x)):\n",
    "        res += abs(x[i] - y[i]) ** p\n",
    "    return res ** (1 / p)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "def cosineSimilarity(x, y):\n",
    "    res, a, b = 0, 0, 0\n",
    "    for i in range(len(x)):\n",
    "        res += x[i] * y[i]\n",
    "        a += x[i] ** 2\n",
    "        b += y[i] ** 2\n",
    "    a = a ** (1 / 2)\n",
    "    b = b ** (1 / 2)\n",
    "    return res / a / b\n",
    "    \n",
    "\n",
    "metrics = [lambda x, y: minkowskiDistance(x, y, 1), \n",
    "           lambda x, y: minkowskiDistance(x, y, 2)\n",
    "          ]\n",
    "#lambda x, y: cosineSimilarity(x, y)]    \n",
    "\n",
    "metric_names = dict()\n",
    "metric_names[metrics[0]] = 'minkowski with p = 1'\n",
    "metric_names[metrics[1]] = 'minkowski with p = 2'\n",
    "#metric_names[metrics[2]] = 'cosine'\n",
    "\n",
    "#for metric in metrics:\n",
    "#    print(metric((1, 1), (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = [\n",
    "    (lambda x: 1 / 2, 'uniform'),\n",
    "    (lambda x: 1 - abs(x), 'triangular'),\n",
    "    (lambda x: 3 / 4 * (1 - x * x), 'parabolic'),\n",
    "    (lambda x: (1 - x ** 2) ** 2 * 15 / 16, 'quartic')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(k, length):\n",
    "    one_fold_length = length // k\n",
    "    others = length % k\n",
    "    indexies = [i for i in range(length)]\n",
    "    result = list()\n",
    "    for i in range(k):\n",
    "        test_suit = list()\n",
    "        train_suit = list()\n",
    "\n",
    "        for j in range(one_fold_length):\n",
    "            index = indexies[int(np.random.uniform(0, len(indexies))) % len(indexies)]\n",
    "            test_suit.append(index)\n",
    "            indexies.remove(index)\n",
    "        if others > 0:\n",
    "            others -= 1\n",
    "            index = indexies[int(np.random.uniform(0, len(indexies))) % len(indexies)]\n",
    "            test_suit.append(index)\n",
    "            indexies.remove(index)\n",
    "        \n",
    "        for j in range(length):\n",
    "            if j not in test_suit:\n",
    "                train_suit.append(j)\n",
    "        \n",
    "        result.append((train_suit, test_suit))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "green = [[], []]\n",
    "blue = [[], []]\n",
    "\n",
    "for x in np.arange(-1, 1.5, 0.01):\n",
    "    for y in np.arange(-1, 1.5, 0.01):\n",
    "        predicted = predict_class(best_neighbor, best_metric, best_data[0], best_data[1], best_data[2](x, y), best_kernel)\n",
    "\n",
    "        if (predicted == 0):\n",
    "            green[0].append(x)\n",
    "            green[1].append(y)\n",
    "        else:\n",
    "            blue[0].append(x)\n",
    "            blue[1].append(y)\n",
    "\n",
    "plt.title(best_string)\n",
    "plt.plot(green[0], green[1], 'g.', blue[0], blue[1], 'b.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAllPoints(simpleData[0], simpleData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(x, classes):\n",
    "    temp = classes[x]\n",
    "    if temp == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def lagrange(lambdas, train_suit, classes, kernel):\n",
    "    result = -sum(lambdas)\n",
    "    \n",
    "    for i in range(len(train_suit)):\n",
    "        for j in range(len(train_suit)):\n",
    "            x_i = train_suit[i]\n",
    "            x_j = train_suit[j]\n",
    "            result += lambdas[i] * lambdas[j] * get_class(x_i, classes) * get_class(x_j, classes) * kernel(x_i, x_j)\n",
    "    return result\n",
    "\n",
    "def get_constraint(train_suit, classes):\n",
    "    def constraint(x):\n",
    "        result = 0\n",
    "        for i in range(len(x)):\n",
    "            result += get_class(train_suit[i], classes) * x[i]\n",
    "        return result\n",
    "    return constraint\n",
    "    \n",
    "def predict_svm(point, kernel, w, w0):\n",
    "    result = kernel(point, w) - w0\n",
    "    if result < 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# training_suit = []\n",
    "# classes = {}\n",
    "\n",
    "def SVM(data, classes, kernel, C, cv_params = (1, 10)):\n",
    "\n",
    "    tfold, kfold = cv_params\n",
    "    kfold_index = k_fold_cv(kfold, len(data))\n",
    "    max_score = 0\n",
    "    TP  = [0, 0]\n",
    "    FP  = [0, 0]\n",
    "    ALL = [0 , 0]\n",
    "    for train_suit, test_suit in kfold_index:\n",
    "        training_suit = [data[i] for i in train_suit]\n",
    "        testing_suit = [data[i] for i in test_suit]\n",
    "        def lagrange_gradient(x, *args):\n",
    "            def dv_dxi(i):\n",
    "                result = -1\n",
    "                for j in range(len(x)):\n",
    "                    x_i = training_suit[i]\n",
    "                    x_j = training_suit[j]\n",
    "\n",
    "                    result += x[j] * get_class(x_i, classes) * get_class(x_j, classes) * kernel(x_i, x_j)\n",
    "                return result\n",
    "            return [dv_dxi(i) for i in range(len(x))]\n",
    "\n",
    "\n",
    "        lambdas = sopt.minimize(lagrange, \n",
    "                                np.array([0 for i in range(len(training_suit))]), \n",
    "                                (training_suit, classes, kernel), \n",
    "                                jac=lagrange_gradient, \n",
    "                                bounds=[(0,C) for i in range(len(training_suit))],\n",
    "                                constraints={'type':'eq', 'fun':get_constraint(training_suit, classes)})\n",
    "\n",
    "        w = np.array([0 for i in range(len(training_suit[0]))], dtype='float64')\n",
    "        for i in range(len(training_suit)):\n",
    "            lambda_i = lambdas.x[i]\n",
    "            y_i = get_class(training_suit[i], classes)\n",
    "            x_i = training_suit[i]\n",
    "            w += np.array([lambda_i * y_i * x_i[j] for j in range(len(x_i))], dtype='float64')\n",
    "            \n",
    "        w0 = 0\n",
    "        count = 0\n",
    "        for i in range(len(lambdas.x)):\n",
    "            lambda_i = lambdas.x[i]\n",
    "            if lambda_i > 0:\n",
    "                w0 += kernel(w, training_suit[i]) - get_class(training_suit[i], classes)\n",
    "                count += 1\n",
    "        if count != 0:\n",
    "            w0 /= count\n",
    "        \n",
    "        for point in testing_suit:\n",
    "            predicted = int(predict_svm(point, kernel, w, w0))\n",
    "            real_class = int(classes[point])\n",
    "            if predicted == real_class:\n",
    "                TP[predicted] += 1\n",
    "            else:\n",
    "                FP[predicted] += 1\n",
    "            ALL[real_class] += 1\n",
    "        \n",
    "    if TP[1] > 0:\n",
    "        recall = TP[1] / ALL[1]\n",
    "        precision = TP[1] / (TP[1] + FP[1])\n",
    "        # F1 measure\n",
    "        return 2 * (precision * recall) / (precision + recall), (kernel, w, w0)\n",
    "    return 0, (kernel, w, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_kernel(x, y):\n",
    "    return sum(np.array(x) * np.array(y))\n",
    "\n",
    "def square_kernel(x, y):\n",
    "    return simple_kernel(x, y) ** 2\n",
    "\n",
    "def paraboloid_kernel(x, y):\n",
    "    return simple_kernel([x[0], x[1], x[0]**2 + x[1]**2], [y[0], y[1], y[0]**2 + y[1]**2])\n",
    "\n",
    "def parab(data):\n",
    "    w = np.array([0, 0], dtype='float64')\n",
    "    input_data, classes, transform_name, transform = data\n",
    "    for point in input_data:\n",
    "        w += np.array(point, dtype='float64')\n",
    "    w /= len(data)\n",
    "    def kernel(x, y):\n",
    "        return simple_kernel([x[0], x[1], (x[0] - w[0])**2 + (x[1] - w[1])**2], [y[0], y[1], (y[0] - w[0])**2 + (y[1] - w[1])**2])\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def paraboloid_kernel2(x, y):\n",
    "    return square_kernel([x[0], x[1], x[0]**2 + x[1]**2], [y[0], y[1], y[0]**2 + y[1]**2])\n",
    "\n",
    "def gaussianKernel(sigma=1):\n",
    "    FG = lambda x : np.array([(x[0]**2 + x[1]**2) , x[0], x[1]])\n",
    "    return lambda x, y: np.exp(-np.dot(FG(np.array(x) - np.array(y)),  FG(np.array(x) - np.array(y))) / (2 * (sigma ** 2)))\n",
    "\n",
    "bikernels = [(parab(simpleData), 'square paraboloid'),\n",
    "             (gaussianKernel(1), 'gaussian'),\n",
    "             (simple_kernel, '<x,y>'),\n",
    "             (square_kernel, '<x,y>^2'),\n",
    "             (paraboloid_kernel, 'simple paraboloid'),\n",
    "             ]\n",
    "\n",
    "svm_data = [data[0], data[-2], data[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "bext = None\n",
    "for kfold in [5]:\n",
    "    for kernel in bikernels:\n",
    "        for input_data, classes, transform_name, transform in svm_data:\n",
    "            for C in [0.114]:\n",
    "                score, tmp = SVM(input_data, classes, kernel[0], C, cv_params=(1,kfold))\n",
    "                if current < score:\n",
    "                    current = score\n",
    "                    bext = tmp\n",
    "                print(kernel[1], transform_name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_predict_class(point, learningSet, classes, knn_k, knnMetric, knnKernel):\n",
    "    distances = [(knnMetric(lpoint, point), lpoint) for lpoint in learningSet]\n",
    "    distances.sort()\n",
    "    d = distances[knn_k][0]\n",
    "    if (d == 0):\n",
    "        d = 1\n",
    "    s = [0, 0]\n",
    "    for j in range(knn_k):\n",
    "        dist, p = distances[j]\n",
    "        s[int(classes[p])] += knnKernel(dist / d)\n",
    "    if (s[0] > s[1]):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def getKnn(learningSet, testingSet, classes, knn_k, knnMetric, knnKernel):\n",
    "    result = dict()\n",
    "    for point in testingSet:\n",
    "        result[point] = knn_predict_class(point, learningSet, classes, knn_k, knnMetric, knnKernel)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def SVM2(learningSet, testingSet, classes, kernel, C):\n",
    "    def lagrange_gradient(x, *args):\n",
    "        def dv_dxi(i):\n",
    "            result = -1\n",
    "            for j in range(len(x)):\n",
    "                x_i = learningSet[i]\n",
    "                x_j = learningSet[j]\n",
    "\n",
    "                result += x[j] * get_class(x_i, classes) * get_class(x_j, classes) * kernel(x_i, x_j)\n",
    "            return result\n",
    "        \n",
    "        return [dv_dxi(i) for i in range(len(x))]\n",
    "\n",
    "    lambdas = sopt.minimize(lagrange, \n",
    "                            np.array([0 for i in range(len(learningSet))]),\n",
    "                            (learningSet, classes, kernel), \n",
    "                            jac=lagrange_gradient, \n",
    "                            bounds=[(0,C) for i in range(len(learningSet))],\n",
    "                            constraints={'type':'eq', 'fun':get_constraint(learningSet, classes)})\n",
    "\n",
    "    w = np.array([0 for i in range(len(learningSet[0]))], dtype='float64')\n",
    "    for i in range(len(learningSet)):\n",
    "        lambda_i = lambdas.x[i]\n",
    "        y_i = get_class(learningSet[i], classes)\n",
    "        x_i = learningSet[i]\n",
    "        w += np.array([lambda_i * y_i * x_i[j] for j in range(len(x_i))], dtype='float64')\n",
    "            \n",
    "    w0 = 0\n",
    "    count = 0\n",
    "    for i in range(len(lambdas.x)):\n",
    "        lambda_i = lambdas.x[i]\n",
    "        if lambda_i > 0:\n",
    "            w0 += kernel(w, learningSet[i]) - get_class(learningSet[i], classes)\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        w0 /= count\n",
    "        \n",
    "    res = {}\n",
    "        \n",
    "    for point in testingSet:\n",
    "        res[point] = int(predict_svm(point, kernel, w, w0))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConfusion(data, pClasses, trueClasses):\n",
    "    true_positive = [0, 0]\n",
    "    false_positive = [0, 0]\n",
    "    \n",
    "    for point in data:\n",
    "        trueClass = trueClasses[point]\n",
    "        predicted = pClasses[point]\n",
    "        \n",
    "        if predicted == trueClass:\n",
    "            true_positive[predicted] += 1\n",
    "        else:\n",
    "            false_positive[predicted] += 1\n",
    "    \n",
    "    return (true_positive, false_positive)\n",
    "    \n",
    "    \n",
    "\n",
    "def getF1Score(conf):\n",
    "    true_positive, false_positive = conf\n",
    "    all_points = [0, 0]\n",
    "    all_points[0] = true_positive[0] + false_positive[1]\n",
    "    all_points[1] = true_positive[1] + false_positive[0]\n",
    "       \n",
    "    if true_positive[1] > 0:\n",
    "        recall = true_positive[1] / all_points[1]\n",
    "        precision = true_positive[1] / (true_positive[1] + false_positive[1])\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# H0: difference between predicted classes follows a symmetric distribution around zero\n",
    "# H1: difference between predicted does not follow a symmetric distribution around zero.\n",
    "\n",
    "# reference link: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
    "\n",
    "# two-sided, for one-sided count only + or - values\n",
    "# Significance Level: 0.01 or 0.05?\n",
    "def getWilcoxonRank(res1, res2):\n",
    "    diff = []\n",
    "    for i in range(len(res1)):\n",
    "        if (res2[i] - res1[i] != 0):\n",
    "            m = abs(res2[i] - res1[i])\n",
    "            diff.append([m, (res2[i] - res1[i]) / m, 0])\n",
    "    diff.sort()\n",
    "    n = len(diff)\n",
    "\n",
    "    for r in range(n):\n",
    "        diff[r][2] = r + 1\n",
    "    \n",
    "    i = 0\n",
    "    while (i < n):\n",
    "        s = 0\n",
    "        prev = i\n",
    "        while ((i < n) and (diff[i][0] == diff[prev][0])):\n",
    "            s += diff[i][2]\n",
    "            i += 1\n",
    "        if (i - prev > 1):\n",
    "            for t in range(prev, i):\n",
    "                diff[t][2] = s / (i - prev)\n",
    "    \n",
    "    ans_m = 0\n",
    "    ans_p = 0\n",
    "    for i in range(n):\n",
    "        if (diff[i][1] * diff[i][2] < 0):\n",
    "            ans_m -= diff[i][1] * diff[i][2]\n",
    "        else:\n",
    "            ans_p += diff[i][1] * diff[i][2]\n",
    "    \n",
    "    \n",
    "    #z = \n",
    "    #prob = 2. * distributions.norm.sf(abs(z))\n",
    "    #return (ans, z, prob)\n",
    "    \n",
    "    return ans_m, ans_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCV(data, k):\n",
    "    cData = data[::]\n",
    "    random.shuffle(cData)\n",
    "    foldSize = len(cData) // k\n",
    "    folds = [cData[i * foldSize : (i + 1) * foldSize] for i in range(k)]\n",
    "    q = 0\n",
    "    for i in range(k * foldSize, len(cData)):\n",
    "        folds[q].append(cData[i])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(data, classes, name, transform) for every in data = [simpleData, sumData, polarData, polarData2, wideData]\n",
    "\n",
    "k = 12\n",
    "\n",
    "for d, classes, name, tr in [wideData]:\n",
    "    \n",
    "    folds = getCV(d, k)\n",
    "    \n",
    "    r1, r2 = [], []\n",
    "    rr1, rr2 = {}, {}\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        testingSet = folds[i] \n",
    "        learningSet = []\n",
    "        for j in range(len(folds)):\n",
    "            if (j != i):\n",
    "                learningSet += folds[j]\n",
    " \n",
    "\n",
    "       # knnClasses, svmClasses = compareMethods(d, classes, 6, 4, , , 0)\n",
    "\n",
    "        metr = lambda x, y: minkowskiDistance(x, y, 1)\n",
    "        kern = lambda x: 1 / 2\n",
    "    \n",
    "        knnClasses = getKnn(learningSet, testingSet, classes, 4, metr, kern)\n",
    "        svmClasses = SVM2(learningSet, testingSet, classes, simple_kernel, 8)\n",
    "        \n",
    "        r1.append(getF1Score(getConfusion(testingSet, knnClasses, classes)))\n",
    "        r2.append(getF1Score(getConfusion(testingSet, svmClasses, classes)))\n",
    "        \n",
    "        rr1.update(knnClasses)\n",
    "        rr2.update(svmClasses)\n",
    "            \n",
    "    \n",
    "    wr = getWilcoxonRank(r1, r2)\n",
    "    print(len(r1))\n",
    "    wr2 = scipy.stats.wilcoxon(r2, r1)\n",
    "    print(\"WR:\", wr)\n",
    "    print(\"WR2:\", wr2)\n",
    "    \n",
    "    \n",
    "    print(\"knn f1:\", getF1Score(getConfusion(d, rr1, classes)))\n",
    "    print(\"svm f1:\", getF1Score(getConfusion(d, rr2, classes)))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "# можно еще f1-score и confusion-matrix посчитать\n",
    "# tp, fp = getConfusion(predictedClasses)\n",
    "# f1 = getF1Score((tp, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
